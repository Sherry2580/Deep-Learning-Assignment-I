{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31a4d5-7318-43aa-b7dc-9d09dcec91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def resize_with_aspect_ratio(image, target_size=(256, 256)):\n",
    "    height, width = image.shape[:2]\n",
    "    target_width, target_height = target_size\n",
    "    width_ratio = target_width / width\n",
    "    height_ratio = target_height / height\n",
    "    ratio = min(width_ratio, height_ratio)\n",
    "    resized_image = cv2.resize(image, (int(width * ratio), int(height * ratio)), interpolation=cv2.INTER_LINEAR)\n",
    "    return resized_image\n",
    "\n",
    "def extract_SIFT_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return descriptors\n",
    "\n",
    "def build_vocab(images, n_clusters=50):\n",
    "    descriptor_list = []\n",
    "    for img in images:\n",
    "        if img is not None:\n",
    "            descriptors = extract_SIFT_features(img)\n",
    "            if descriptors is not None:\n",
    "                descriptor_list.extend(descriptors.astype(np.float32))\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=n_clusters*3)\n",
    "    descriptor_array = np.array(descriptor_list, dtype=np.float32)\n",
    "    kmeans.fit(descriptor_array)\n",
    "    return kmeans\n",
    "\n",
    "def bag_of_words_histogram(image, vocab_model):\n",
    "    descriptors = extract_SIFT_features(image)\n",
    "    if descriptors is None:\n",
    "        return np.zeros(vocab_model.n_clusters, np.float32)\n",
    "    descriptors = descriptors.astype(np.float32)\n",
    "    predict = vocab_model.predict(descriptors)\n",
    "    hist, _ = np.histogram(predict, bins=np.arange(vocab_model.n_clusters+1), density=True)\n",
    "    return hist\n",
    "\n",
    "def load_images_and_labels(file_path, vocab_model, target_size=(256, 256)):\n",
    "    imgs, labels = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines, desc=\"Loading and processing images\"):\n",
    "            file_name, label = line.strip().split(' ')\n",
    "            image = cv2.imread(file_name)\n",
    "            if image is not None:\n",
    "                resized_image = resize_with_aspect_ratio(image, target_size)\n",
    "                bow_hist = bag_of_words_histogram(resized_image, vocab_model)\n",
    "                imgs.append(bow_hist)\n",
    "                labels.append(int(label))\n",
    "    return np.array(imgs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f069a6-a235-4ed0-9509-99b60e8e2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [cv2.imread(line.split()[0]) for line in tqdm(open('train.txt', 'r'), desc=\"Building vocab\")]\n",
    "vocab_model = build_vocab(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209a952-c4d6-4082-bce7-8467feea89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_images_and_labels('train.txt', vocab_model)\n",
    "tx, ty = load_images_and_labels('test.txt', vocab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b51793-d4d5-4550-8131-6e4d4295305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"訓練數據的圖像數據形狀:\", x.shape)\n",
    "print(\"訓練數據的標籤數據形狀:\", y.shape)\n",
    "print(\"測試數據的圖像數據形狀:\", tx.shape)\n",
    "print(\"測試數據的標籤數據形狀:\", ty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46719d64-e622-4162-94f9-256bef46f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, algorithm='auto')\n",
    "knn_classifier.fit(x, y)\n",
    "\n",
    "y_pred = knn_classifier.predict(tx)\n",
    "\n",
    "accuracy = accuracy_score(ty, y_pred)\n",
    "f1 = f1_score(ty, y_pred, average='weighted')\n",
    "\n",
    "print(f\"SIFT + KNN準確率: {accuracy:.4f}\")\n",
    "print(f\"F1分数: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f73aaa-efab-4425-9e53-328a1fe1e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_model.fit(x, y)\n",
    "\n",
    "y_pred = rf_model.predict(tx)\n",
    "\n",
    "accuracy = accuracy_score(ty, y_pred)\n",
    "f1 = f1_score(ty, y_pred, average='weighted')\n",
    "\n",
    "print(f\"SIFT + RF準確率: {accuracy:.4f}\")\n",
    "print(f\"F1分數: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceebb95-d2e0-4d3e-a086-8808b85529af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(C=1.0, kernel='rbf', verbose=False)\n",
    "svm_classifier.fit(x, y)\n",
    "\n",
    "y_pred = svm_classifier.predict(tx)\n",
    "\n",
    "accuracy = accuracy_score(ty, y_pred)\n",
    "f1 = f1_score(ty, y_pred, average='weighted')\n",
    "\n",
    "print(f\"SIFT + svm準確率: {accuracy:.4f}\")\n",
    "print(f\"F1分數: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplhw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
